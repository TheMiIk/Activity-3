\documentclass{article}
\usepackage{graphicx}

\title{Algorithms and their respective efficiency. }
\author{Adrian Bistrae \\
Faculty of Informatics and Mathematics, \\
West University of Timisoara, \\
}
\date{May 2023}

\begin{document}

\maketitle
\begin{abstract}
The purpose of this paper is to show the difference in efficiency between different sorting algorithms. This outcome will be achieved and explained through different case studies.
\end{abstract}
\pagebreak
\tableofcontents
\pagebreak

\section{Introduction}
\subsection{Overview}
There are various sorting algorithms out there that vary depending on their efficiency, speeds and complexity. The aim of this documentation is to show which algorithms are better suited for common use, and overall which are the fastest ones. To do so we will be conducting various case studies.

\subsection{Solution (in short)}
In order to be able to achieve the results needed for a good comparison we will need multiple code bases ran under the pretext of which will be able to compute the fastest. These said codes will be ran in the C programming language therefore the results will be specific to C. \textit{(results may vary based on the language used)}
\\
\textbf{All case studies and code bases have been created by the author.}

\subsection{Paper Contents}
The following pages will include short explanations of each algorithm that has been used, as well as a case study per algorithm. There will be a comparison of the said algorithms towards the end of the documentation, summarizing the end results.
\pagebreak
\section{Algorithms}
\subsection{A basic understanding}
When it comes to computer science an algorithm is a list set of instructions, used to solve problems or perform tasks, based on the understanding of available alternatives.They are specifications for performing calculations, data processing, automated reasoning or decision making. [1]
\subsection{Sorting Algorithms}
This paper focuses on a subsection of the overall algorithm topic, namely sorting algorithms. Sorting algorithms are a method of organizing/reorganizing large numbers into specific orders.
\\
Researchers have attempted in past to develop algorithms efficiently in terms of
optimum memory requirement and minimum time requirement i.e., Time or Space Complexities. Algorithmic
complexity of sorting algorithm is generally written in a form known as Big-O notation, where the O represents the
complexity of the algorithm and a value n represents the size of the set the algorithm is run against. For example, O(n)
means that an algorithm has a linear complexity. %trebe bib
\\
The algorithms which have been studied and tested are the following:
\begin{itemize}
    \item Bucket sort
    \item Quick sort
    \item Heap sort
    \item Radix sort
    \item Bubble sort
    \item Inseration sort
    \item Merge sort
    \item Selection sort
\end{itemize}
These specified sorting algorithms fall into 2 categories:
\begin{itemize}
    \item Non-comparison based \textit{(Bucket,Radix)}
    \item Comparison based \textit{(Quick,Heap,Bubble,Inseration,Merge,Selection)}
\end{itemize}
\pagebreak
\subsection{Non-comparison based sorting algorithms}
\subsubsection{Bucket sort}
Bucket Sort is a sorting method that subdivides the given data into various buckets depending on certain characteristic
order, thus partially sorting them in the first go. Then depending on the number of entities in each bucket, it employs
either bucket sort again or some other sort. Bucket sort runs in linear time on an average. Bucket sort is stable. It
assumes that the input is generated by a random process that distributes elements uniformly over the interval 1 to m. [2]
\subsubsection{Radix sort}
A radix sort is an algorithm that can rearrange integer representations based on the processing of individual digits in
such a way that the integer representations are eventually in either ascending or descending order. Integer representations
can be used to represent things such as strings of characters (names of people, places, things, the words and characters,
dates, etc.) and floating point numbers as well as integers. So, anything which can be represented as an ordered sequence
of integer representations can be rearranged to be in order by a radix sort. [2]
\subsection{Comparison based sorting algorithms}
\subsubsection{Quick sort}
Quick sort was developed by Sir Charles Antony Richard Hoare (Hoare 1962). It belongs to the family of
exchange sorting. Quick sort is an in-place, divide-and-conquer, massively recursive sort and it is also known as a
partition-exchange sort.
\subsubsection{Heap sort}
Heap sort can be thought of like selection sort, heap sort divides its input into a sorted and an unsorted region, and it shrinks the unsorted region by extracting the largest element from it and inserting it into the sorted region.
\subsubsection{Selection sort}
 Selection sort belongs to the family of in-place comparison sorting. This algorithm is called selection sort because
it works by selecting a minimum element in each pass (step) of the sort. In this method, to sort the data in increasing
order, the first element is compared with all the elements. If first element is greater than smallest element than
interchanged the position of elements. So after the first pass, the smallest element is placed at the first position. The same
procedure is repeated for 2nd element and so on until the element of list is sorted [3]
\subsubsection{Merge sort}
Merge sort was invented by John von Neumann and belongs to the family of comparison-based sorting. This
algorithm is also based on Divide-and-Conquer approach.
\subsubsection{Insertion sort}
Insertion sort is a naive algorithm that belongs to the family of comparison sorting. Insertion sort is an example of
an incremental algorithm; it builds the sorted sequence one number at a time. In this sorting we can read the given
elements from 1 to n, inserting each element into its proper position through comparison. Here n-1 pass (step) are
require for sorting time. [3]
\subsubsection{Bubble sort}
Bubble sort belongs to the family of comparison sorting. The Bubble Sort is the simplest sorting technique and
multiple swapping process to apply to every pass, in which smallest data element are moved to the top of
the list. In this sorting method, we compare the adjacent members of the list to be sorted, if the top of item is greater than
the item immediately below it, they are swapped. Unfortunately, it is a slowest sorting method as a compare selection and
insertion sort. [3]
\pagebreak
\section{Efficiency Test}
In order to define which algorithm is the best we will be grading the algorithms based on different criteria: efficiency and complexity. The grading will be also given based on the sorting type.
The case studies consist of testing the capability of each algorithm when it comes to sorting a large number of integers. (For this study the amount is half a million)
\subsection{Non-comparison based algorithms study}
\textbf{Bucket sort used for the case study:}
\\\\
\includegraphics[width = 0.5\textwidth]{images/Screenshot_38.png}
\includegraphics[width = 0.5\textwidth]{images/Screenshot_39.png}
\\\\
Upon running the bucket sort code we can deduct the following things:
\begin{itemize}
    \item Time taken: 1:06.72 minutes
    \item Time complexity: $O(n + k^2)$
    \item Space complexity: $O(n+k)$    
\end{itemize}
\pagebreak
\textbf{Radix sort used:}
\\\\
\includegraphics[width= 0.9\textwidth]{images/Screenshot_40.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_41.png}
\\\\
Upon running the radix sort code we can deduct the following things:
\begin{itemize}
    \item Time taken: 1:27.43 minutes
    \item Time complexity: O(d*(n+k)) \textit{(where d is the number of digits)}
    \item Space complexity: O(n)
\end{itemize}

\textbf{Now that we've ran both studies in this category we can affirm which algorithm is better:}
\\\\
\begin{tabular}{|c|c|c|c|}
\hline
  Algorithm & Time taken & Time complexity & Space complexity  \\
\hline
 Bucket sort& 1:06.72 minutes &$O(n + k^2)$&$O(n+k)$ \\
\hline
 Radix sort& 1:27.43 minutes &O(d*(n+k))&O(n) \\
\hline
\end{tabular}
\\\\\\
\textbf{Judging by the following table, bucket sort can be deemed as more efficient when it comes to non-comparison based algorithms, not only due to the speed difference but also due to it being less complex when it comes to implementation. (specifically in C in this study)}
\pagebreak
\subsection{Comparison based algorithms study}
\textbf{Quick sort code used for the study:}
\\\\
\includegraphics[width= 0.6\textwidth]{images/Screenshot_42.png}
\includegraphics[width= 0.6\textwidth]{images/Screenshot_43.png}
\\\\
Upon running the quick sort code we can deduct the following things:
\begin{itemize}
    \item Time taken:  1:25.30 minutes
    \item Time complexity: $O(n^2)$
    \item Space complexity: O(log(n))
\end{itemize}

\textbf{Heap sort code used for the study:}
\\\\
\includegraphics[width= 0.6\textwidth]{images/Screenshot_44.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_45.png}

Upon running the heap sort code we can deduct the following things:
\begin{itemize}
    \item Time taken:  0:01.54 minutes
    \item Time complexity: O(log(n))
    \item Space complexity: O(1)
\end{itemize}

\textbf{Selection sort code used for the study:}
\\\\
\includegraphics[width= 0.6\textwidth]{images/Screenshot_46.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_47.png}
\\\\
Upon running the selection sort code we can deduct the following things:
\begin{itemize}
    \item Time taken:  10:02.20 minutes
    \item Time complexity: $O(n^2)$
    \item Space complexity: O(n) 
\end{itemize}
\pagebreak
\textbf{Merge sort code used for the study:}
\\\\
\includegraphics[width= 0.6\textwidth]{images/Screenshot_48.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_49.png}
\\\\
Upon running the merge sort code we can deduct the following things:
\begin{itemize}
    \item Time taken:   0:24.19 minutes
    \item Time complexity: O(n log(n))
    \item Space complexity: O(n) 
\end{itemize}

\textbf{Insertion sort code used for the study:}
\\\\
\includegraphics[width= 0.5\textwidth]{images/Screenshot_50.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_51.png}
\\\\

 Upon running the insertion sort code we can deduct the following things:
 \begin{itemize}
    \item Time taken:    9:08.25 minutes
    \item Time complexity: $O(n^2)$
    \item Space complexity: O(n) 
\end{itemize}

\textbf{Bubble sort code used for the study:}
\\\\
\includegraphics[width= 0.7\textwidth]{images/Screenshot_52.png}
\includegraphics[width= 0.5\textwidth]{images/Screenshot_53.png}
\\\\

Upon running the bubble sort code we can deduct the following things:
 \begin{itemize}
    \item Time taken:  10:02.03 minutes
    \item Time complexity: $O(n^2)$
    \item Space complexity: O(n) 
\end{itemize}
\pagebreak
\textbf{Now that we've ran the comparison based algorithms as well, we can begin to grade them as well in a similar fashion as the non-comparison based ones.}
\\\\
\begin{tabular}{|c|c|c|c|}
\hline
  Algorithm & Time taken & Time complexity & Space complexity  \\
\hline
 Heap sort& 0:01.54 minutes &O(log(n))&O(1) \\ 
\hline
 Merge sort& 0:24.19 minutes&O(n log(n))&O(n) \\
\hline
 Quick sort& 1:25.30 minutes &$O(n^2)$&O(log(n)) \\
\hline
 Insertion sort& 9:08.25 minutes&$O(n^2)$&O(n) \\
\hline
 Bubble sort& 10:02.03 minutes&$O(n^2)$&O(n) \\
\hline
 Selection sort& 10:02.20 minutes &$O(n^2)$&O(n) \\
\hline
\end{tabular}
\\\\
Looking at the table, we can notice the fact that heap sort has completed the task most efficiently while selection sort has taken the most time out of all the comparison based algorithms.
\\
In terms on implementation heap sort is the most complex one while insertion and bubble sort are the easiest to implement.
\subsection{Overall efficiency}

After looking over both algorithm tables, we can unite them in order to get a better picture of the efficiency of each sorting algorithm despite category.
\\\\
\begin{tabular}{|c|c|c|c|}
\hline
  Algorithm & Time taken & Time complexity & Space complexity  \\
\hline
 Heap sort& 0:01.54 minutes &O(log(n))&O(1) \\ 
\hline
 Merge sort& 0:24.19 minutes&O(n log(n))&O(n) \\
\hline
 Bucket sort& 1:06.72 minutes &$O(n + k^2)$&$O(n+k)$ \\
\hline
 Quick sort& 1:25.30 minutes &$O(n^2)$&O(log(n)) \\
\hline
 Radix sort& 1:27.43 minutes &O(d*(n+k))&O(n) \\
\hline
 Insertion sort& 9:08.25 minutes&$O(n^2)$&O(n) \\
\hline
 Bubble sort& 10:02.03 minutes&$O(n^2)$&O(n) \\
\hline
 Selection sort& 10:02.20 minutes &$O(n^2)$&O(n) \\
\hline
\end{tabular}
\section{Parting words}

In conclusion, after reviewing the overall table we can notice that not much has changed. Every single sorting algorithm that has been a part of the study can still be deemed as useful and usable however, in the case of Insertion/Bubble/Selection sort efficiency is being traded in for ease of use.
\pagebreak
\section{Bibliography}
 International Institute in Geneva, ICC 20, Rte de Pr√©-Bois - 1215 Geneva 15 - Switzerland [1]
\\\\
Rohit Joshi, Govind Singh Panwar, Preeti Pathak - International Journal of
Emerging Research in Management and Technology
ISSN: 2278-9359 (Volume-2, Issue-12) [2]
\\\\
Kamlesh Kumar Pandey, Rajesh Kumar Bunkar - International Journal of Advanced Research in Computer Science and Software Engineering [3]




\end{document}
